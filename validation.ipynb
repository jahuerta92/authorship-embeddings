{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_books = pd.read_csv('local_data/book_test.csv')\n",
    "test_mails = pd.read_csv('local_data/mail_test.csv')\n",
    "test_blogs = pd.read_csv('local_data/blog_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>old_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_14</td>\n",
       "      <td>[0, 1187, 41732, 6, 5, 754, 14, 44959, 74, 210...</td>\n",
       "      <td>&lt;s&gt;ndoubtedly, the fact that Socialism would r...</td>\n",
       "      <td>The Soul of Man under Socialism</td>\n",
       "      <td>Wilde, Oscar</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>396</td>\n",
       "      <td>{'Socialism'}</td>\n",
       "      <td>PG1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_14</td>\n",
       "      <td>[167, 54, 50118, 10800, 33037, 1070, 24, 6, 98...</td>\n",
       "      <td>those who\\ncontemplated it, so, in the presen...</td>\n",
       "      <td>The Soul of Man under Socialism</td>\n",
       "      <td>Wilde, Oscar</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>396</td>\n",
       "      <td>{'Socialism'}</td>\n",
       "      <td>PG1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_14</td>\n",
       "      <td>[122, 19, 559, 50118, 11017, 131, 114, 6, 11, ...</td>\n",
       "      <td>now with political\\npower; if, in a word, we ...</td>\n",
       "      <td>The Soul of Man under Socialism</td>\n",
       "      <td>Wilde, Oscar</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>396</td>\n",
       "      <td>{'Socialism'}</td>\n",
       "      <td>PG1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_14</td>\n",
       "      <td>[34, 5812, 7, 224, 24, 4, 1437, 509, 23154, 24...</td>\n",
       "      <td>has begun to say it.  One hears it now from e...</td>\n",
       "      <td>The Soul of Man under Socialism</td>\n",
       "      <td>Wilde, Oscar</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>396</td>\n",
       "      <td>{'Socialism'}</td>\n",
       "      <td>PG1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_14</td>\n",
       "      <td>[50118, 241, 11312, 6514, 6, 16, 1153, 10, 588...</td>\n",
       "      <td>\\nrebellious, is probably a real personality, ...</td>\n",
       "      <td>The Soul of Man under Socialism</td>\n",
       "      <td>Wilde, Oscar</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>396</td>\n",
       "      <td>{'Socialism'}</td>\n",
       "      <td>PG1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53560</th>\n",
       "      <td>book_960</td>\n",
       "      <td>[1195, 14, 578, 3341, 50118, 1437, 1437, 1437,...</td>\n",
       "      <td>rather that—like\\n    Rome, and Athens, and T...</td>\n",
       "      <td>Crying for the Light; Or, Fifty Years Ago. Vol...</td>\n",
       "      <td>Ritchie, J. Ewing (James Ewing)</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>2</td>\n",
       "      <td>{'England -- Social conditions -- 19th century...</td>\n",
       "      <td>PG36810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53561</th>\n",
       "      <td>book_960</td>\n",
       "      <td>[19171, 4051, 50118, 1437, 1437, 1437, 1787, 6...</td>\n",
       "      <td>usting coal\\n    supply, an overwhelming debt,...</td>\n",
       "      <td>Crying for the Light; Or, Fifty Years Ago. Vol...</td>\n",
       "      <td>Ritchie, J. Ewing (James Ewing)</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>2</td>\n",
       "      <td>{'England -- Social conditions -- 19th century...</td>\n",
       "      <td>PG36810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53562</th>\n",
       "      <td>book_960</td>\n",
       "      <td>[1437, 1437, 1437, 1437, 1437, 1437, 1437, 143...</td>\n",
       "      <td>THE END.\\n                           ...</td>\n",
       "      <td>Crying for the Light; Or, Fifty Years Ago. Vol...</td>\n",
       "      <td>Ritchie, J. Ewing (James Ewing)</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>2</td>\n",
       "      <td>{'England -- Social conditions -- 19th century...</td>\n",
       "      <td>PG36810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53563</th>\n",
       "      <td>book_960</td>\n",
       "      <td>[9, 203, 937, 773, 4, 17, 27, 578, 1215, 26339...</td>\n",
       "      <td>of much general interest.’—_Daily Chronicle_....</td>\n",
       "      <td>Crying for the Light; Or, Fifty Years Ago. Vol...</td>\n",
       "      <td>Ritchie, J. Ewing (James Ewing)</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>2</td>\n",
       "      <td>{'England -- Social conditions -- 19th century...</td>\n",
       "      <td>PG36810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53564</th>\n",
       "      <td>book_960</td>\n",
       "      <td>[50118, 560, 3794, 4, 1437, 96, 5, 173, 137, 2...</td>\n",
       "      <td>\\nto flag.  In the work before us, which is no...</td>\n",
       "      <td>Crying for the Light; Or, Fifty Years Ago. Vol...</td>\n",
       "      <td>Ritchie, J. Ewing (James Ewing)</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>2</td>\n",
       "      <td>{'England -- Social conditions -- 19th century...</td>\n",
       "      <td>PG36810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53565 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                  pretokenized_text  \\\n",
       "0       book_14  [0, 1187, 41732, 6, 5, 754, 14, 44959, 74, 210...   \n",
       "1       book_14  [167, 54, 50118, 10800, 33037, 1070, 24, 6, 98...   \n",
       "2       book_14  [122, 19, 559, 50118, 11017, 131, 114, 6, 11, ...   \n",
       "3       book_14  [34, 5812, 7, 224, 24, 4, 1437, 509, 23154, 24...   \n",
       "4       book_14  [50118, 241, 11312, 6514, 6, 16, 1153, 10, 588...   \n",
       "...         ...                                                ...   \n",
       "53560  book_960  [1195, 14, 578, 3341, 50118, 1437, 1437, 1437,...   \n",
       "53561  book_960  [19171, 4051, 50118, 1437, 1437, 1437, 1787, 6...   \n",
       "53562  book_960  [1437, 1437, 1437, 1437, 1437, 1437, 1437, 143...   \n",
       "53563  book_960  [9, 203, 937, 773, 4, 17, 27, 578, 1215, 26339...   \n",
       "53564  book_960  [50118, 560, 3794, 4, 1437, 96, 5, 173, 137, 2...   \n",
       "\n",
       "                                            decoded_text  \\\n",
       "0      <s>ndoubtedly, the fact that Socialism would r...   \n",
       "1       those who\\ncontemplated it, so, in the presen...   \n",
       "2       now with political\\npower; if, in a word, we ...   \n",
       "3       has begun to say it.  One hears it now from e...   \n",
       "4      \\nrebellious, is probably a real personality, ...   \n",
       "...                                                  ...   \n",
       "53560   rather that—like\\n    Rome, and Athens, and T...   \n",
       "53561  usting coal\\n    supply, an overwhelming debt,...   \n",
       "53562           THE END.\\n                           ...   \n",
       "53563   of much general interest.’—_Daily Chronicle_....   \n",
       "53564  \\nto flag.  In the work before us, which is no...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                        The Soul of Man under Socialism   \n",
       "1                        The Soul of Man under Socialism   \n",
       "2                        The Soul of Man under Socialism   \n",
       "3                        The Soul of Man under Socialism   \n",
       "4                        The Soul of Man under Socialism   \n",
       "...                                                  ...   \n",
       "53560  Crying for the Light; Or, Fifty Years Ago. Vol...   \n",
       "53561  Crying for the Light; Or, Fifty Years Ago. Vol...   \n",
       "53562  Crying for the Light; Or, Fifty Years Ago. Vol...   \n",
       "53563  Crying for the Light; Or, Fifty Years Ago. Vol...   \n",
       "53564  Crying for the Light; Or, Fifty Years Ago. Vol...   \n",
       "\n",
       "                                author  authoryearofbirth  authoryearofdeath  \\\n",
       "0                         Wilde, Oscar             1854.0             1900.0   \n",
       "1                         Wilde, Oscar             1854.0             1900.0   \n",
       "2                         Wilde, Oscar             1854.0             1900.0   \n",
       "3                         Wilde, Oscar             1854.0             1900.0   \n",
       "4                         Wilde, Oscar             1854.0             1900.0   \n",
       "...                                ...                ...                ...   \n",
       "53560  Ritchie, J. Ewing (James Ewing)             1820.0             1898.0   \n",
       "53561  Ritchie, J. Ewing (James Ewing)             1820.0             1898.0   \n",
       "53562  Ritchie, J. Ewing (James Ewing)             1820.0             1898.0   \n",
       "53563  Ritchie, J. Ewing (James Ewing)             1820.0             1898.0   \n",
       "53564  Ritchie, J. Ewing (James Ewing)             1820.0             1898.0   \n",
       "\n",
       "      language  downloads                                           subjects  \\\n",
       "0       ['en']        396                                      {'Socialism'}   \n",
       "1       ['en']        396                                      {'Socialism'}   \n",
       "2       ['en']        396                                      {'Socialism'}   \n",
       "3       ['en']        396                                      {'Socialism'}   \n",
       "4       ['en']        396                                      {'Socialism'}   \n",
       "...        ...        ...                                                ...   \n",
       "53560   ['en']          2  {'England -- Social conditions -- 19th century...   \n",
       "53561   ['en']          2  {'England -- Social conditions -- 19th century...   \n",
       "53562   ['en']          2  {'England -- Social conditions -- 19th century...   \n",
       "53563   ['en']          2  {'England -- Social conditions -- 19th century...   \n",
       "53564   ['en']          2  {'England -- Social conditions -- 19th century...   \n",
       "\n",
       "        old_id  \n",
       "0       PG1017  \n",
       "1       PG1017  \n",
       "2       PG1017  \n",
       "3       PG1017  \n",
       "4       PG1017  \n",
       "...        ...  \n",
       "53560  PG36810  \n",
       "53561  PG36810  \n",
       "53562  PG36810  \n",
       "53563  PG36810  \n",
       "53564  PG36810  \n",
       "\n",
       "[53565 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mail_105</td>\n",
       "      <td>[0, 1620, 47, 32, 2542, 6, 110, 265, 1933, 34,...</td>\n",
       "      <td>&lt;s&gt;As you are aware, your business unit has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mail_105</td>\n",
       "      <td>[16410, 4383, 50118, 28062, 12552, 16, 5, 1850...</td>\n",
       "      <td>Methodology\\nAttached is the proposed ERCOT I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mail_105</td>\n",
       "      <td>[8, 5214, 844, 50118, 627, 595, 183, 1914, 239...</td>\n",
       "      <td>and=20\\nthe current day forecast high tempera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail_105</td>\n",
       "      <td>[2388, 87, 5, 4971, 6, 172, 5, 230, 3632, 3500...</td>\n",
       "      <td>greater than the limits, then the CSC proble=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail_105</td>\n",
       "      <td>[381, 5199, 3293, 4, 5457, 844, 50118, 14773, ...</td>\n",
       "      <td>ERCOT. =20\\nMarket rules dictate that by 0600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123787</th>\n",
       "      <td>mail_56</td>\n",
       "      <td>[515, 322, 1437, 1437, 3401, 680, 162, 1437, 5...</td>\n",
       "      <td>event).   Please include me \\nwhen \\nyou give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123788</th>\n",
       "      <td>mail_56</td>\n",
       "      <td>[16135, 7, 5, 1248, 644, 1105, 6, 3788, 4, 143...</td>\n",
       "      <td>forward to the date January 31, 2000.  It is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123789</th>\n",
       "      <td>mail_56</td>\n",
       "      <td>[1189, 5, 276, 6, 53, 5, 433, 16, 533, 7, 422,...</td>\n",
       "      <td>remains the same, but the media is likely to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123790</th>\n",
       "      <td>mail_56</td>\n",
       "      <td>[530, 13673, 12859, 7, 10, 2257, 31482, 11, 10...</td>\n",
       "      <td>K bug refers to a software glitch in some olde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123791</th>\n",
       "      <td>mail_56</td>\n",
       "      <td>[50118, 133, 15771, 561, 1787, 823, 130, 153, ...</td>\n",
       "      <td>\\nThe pipelines together supply nearly three m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                  pretokenized_text  \\\n",
       "0       mail_105  [0, 1620, 47, 32, 2542, 6, 110, 265, 1933, 34,...   \n",
       "1       mail_105  [16410, 4383, 50118, 28062, 12552, 16, 5, 1850...   \n",
       "2       mail_105  [8, 5214, 844, 50118, 627, 595, 183, 1914, 239...   \n",
       "3       mail_105  [2388, 87, 5, 4971, 6, 172, 5, 230, 3632, 3500...   \n",
       "4       mail_105  [381, 5199, 3293, 4, 5457, 844, 50118, 14773, ...   \n",
       "...          ...                                                ...   \n",
       "123787   mail_56  [515, 322, 1437, 1437, 3401, 680, 162, 1437, 5...   \n",
       "123788   mail_56  [16135, 7, 5, 1248, 644, 1105, 6, 3788, 4, 143...   \n",
       "123789   mail_56  [1189, 5, 276, 6, 53, 5, 433, 16, 533, 7, 422,...   \n",
       "123790   mail_56  [530, 13673, 12859, 7, 10, 2257, 31482, 11, 10...   \n",
       "123791   mail_56  [50118, 133, 15771, 561, 1787, 823, 130, 153, ...   \n",
       "\n",
       "                                             decoded_text  \n",
       "0       <s>As you are aware, your business unit has be...  \n",
       "1        Methodology\\nAttached is the proposed ERCOT I...  \n",
       "2        and=20\\nthe current day forecast high tempera...  \n",
       "3        greater than the limits, then the CSC proble=...  \n",
       "4        ERCOT. =20\\nMarket rules dictate that by 0600...  \n",
       "...                                                   ...  \n",
       "123787   event).   Please include me \\nwhen \\nyou give...  \n",
       "123788  forward to the date January 31, 2000.  It is b...  \n",
       "123789   remains the same, but the media is likely to ...  \n",
       "123790  K bug refers to a software glitch in some olde...  \n",
       "123791  \\nThe pipelines together supply nearly three m...  \n",
       "\n",
       "[123792 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pretokenized_text</th>\n",
       "      <th>decoded_text</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_1000</td>\n",
       "      <td>[0, 2387, 128, 9484, 108, 300, 11, 63, 78, 103...</td>\n",
       "      <td>&lt;s&gt;My 'band' got in its first fight tonight. m...</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_1000</td>\n",
       "      <td>[5, 6613, 489, 110, 5567, 7, 5, 1255, 132, 4, ...</td>\n",
       "      <td>the soil keep your ear to the ground 2. Nirva...</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_1000</td>\n",
       "      <td>[8419, 28989, 102, 21, 269, 205, 11, 24, 4, 98...</td>\n",
       "      <td>travolta was really good in it. so was samuel...</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_1000</td>\n",
       "      <td>[4, 947, 282, 39596, 131, 98, 52, 439, 89, 8, ...</td>\n",
       "      <td>.&amp;nbsp; so we went there and went out to eat a...</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_1000</td>\n",
       "      <td>[282, 39596, 131, 947, 282, 39596, 131, 947, 2...</td>\n",
       "      <td>nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp...</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38765</th>\n",
       "      <td>blog_9938</td>\n",
       "      <td>[4, 280, 18, 45, 205, 142, 6, 71, 70, 6, 42, 1...</td>\n",
       "      <td>. That's not good because, after all, this sit...</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38766</th>\n",
       "      <td>blog_9938</td>\n",
       "      <td>[5919, 6, 6966, 8, 2254, 28852, 13295, 23668, ...</td>\n",
       "      <td>tennis, swim and enjoy nightly bonfires on th...</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38767</th>\n",
       "      <td>blog_9938</td>\n",
       "      <td>[10631, 8, 13404, 95, 7, 1649, 383, 66, 734, 5...</td>\n",
       "      <td>Mom and Dad just to check things out...to see...</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38768</th>\n",
       "      <td>blog_9938</td>\n",
       "      <td>[9, 5761, 38497, 108, 1437, 361, 35, 541, 2784...</td>\n",
       "      <td>of Forest Fires'  9:30 PM   Break for secret ...</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38769</th>\n",
       "      <td>blog_9938</td>\n",
       "      <td>[92, 790, 4, 1437, 231, 4, 1890, 12486, 2682, ...</td>\n",
       "      <td>new house.  6. Unpack stuff at new place  7. ...</td>\n",
       "      <td>33</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38770 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                  pretokenized_text  \\\n",
       "0      blog_1000  [0, 2387, 128, 9484, 108, 300, 11, 63, 78, 103...   \n",
       "1      blog_1000  [5, 6613, 489, 110, 5567, 7, 5, 1255, 132, 4, ...   \n",
       "2      blog_1000  [8419, 28989, 102, 21, 269, 205, 11, 24, 4, 98...   \n",
       "3      blog_1000  [4, 947, 282, 39596, 131, 98, 52, 439, 89, 8, ...   \n",
       "4      blog_1000  [282, 39596, 131, 947, 282, 39596, 131, 947, 2...   \n",
       "...          ...                                                ...   \n",
       "38765  blog_9938  [4, 280, 18, 45, 205, 142, 6, 71, 70, 6, 42, 1...   \n",
       "38766  blog_9938  [5919, 6, 6966, 8, 2254, 28852, 13295, 23668, ...   \n",
       "38767  blog_9938  [10631, 8, 13404, 95, 7, 1649, 383, 66, 734, 5...   \n",
       "38768  blog_9938  [9, 5761, 38497, 108, 1437, 361, 35, 541, 2784...   \n",
       "38769  blog_9938  [92, 790, 4, 1437, 231, 4, 1890, 12486, 2682, ...   \n",
       "\n",
       "                                            decoded_text  age    topic gender  \n",
       "0      <s>My 'band' got in its first fight tonight. m...   16  Student   male  \n",
       "1       the soil keep your ear to the ground 2. Nirva...   16  Student   male  \n",
       "2       travolta was really good in it. so was samuel...   16  Student   male  \n",
       "3      .&nbsp; so we went there and went out to eat a...   16  Student   male  \n",
       "4      nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp...   16  Student   male  \n",
       "...                                                  ...  ...      ...    ...  \n",
       "38765  . That's not good because, after all, this sit...   33   indUnk   male  \n",
       "38766   tennis, swim and enjoy nightly bonfires on th...   33   indUnk   male  \n",
       "38767   Mom and Dad just to check things out...to see...   33   indUnk   male  \n",
       "38768   of Forest Fires'  9:30 PM   Break for secret ...   33   indUnk   male  \n",
       "38769   new house.  6. Unpack stuff at new place  7. ...   33   indUnk   male  \n",
       "\n",
       "[38770 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "from sklearn.metrics import top_k_accuracy_score, accuracy_score\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "def embed(model, texts):\n",
    "    tokenized_texts = TOKENIZER(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    embedding = model(tokenized_texts.input_ids.to(model.device),\n",
    "                      tokenized_texts.attention_mask.to(model.device),\n",
    "                      )\n",
    "    return embedding\n",
    "\n",
    "def embed_transformer(model, texts):\n",
    "    tokenized_texts = TOKENIZER(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    embedding = model(tokenized_texts.input_ids.to(model.device),\n",
    "                      attention_mask = tokenized_texts.attention_mask.to(model.device),\n",
    "                      ).pooler_output\n",
    "    return embedding\n",
    "\n",
    "def evaluate(model, data, top_k=5, N=100, repetitions=1, embed_f=embed):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs, topks = [], []\n",
    "        for _ in tqdm(range(repetitions)):           \n",
    "            authors = data.id.unique().tolist()\n",
    "            shuffle(authors)\n",
    "            random_authors = authors[:N]\n",
    "            anchors, replicas = [], []\n",
    "            for author in random_authors:\n",
    "                anchor, replica = data.loc[author == data.id].decoded_text.sample(2).tolist()\n",
    "                anchors.append(anchor)\n",
    "                replicas.append(replica)\n",
    "            \n",
    "            embedding_anchors = F.normalize(embed_f(model, anchors))\n",
    "            embedding_replicas = F.normalize(embed_f(model, replicas))\n",
    "\n",
    "            preds = embedding_anchors @ embedding_replicas.T\n",
    "            labels = torch.arange(0, len(preds)).numpy()\n",
    "\n",
    "            preds_a = F.softmax(preds, dim=-1)\n",
    "            preds_b = F.softmax(preds.T, dim=-1)\n",
    "\n",
    "            a_acc = accuracy_score(labels, preds_a.argmax(-1).cpu().numpy())\n",
    "            b_acc = accuracy_score(labels, preds_b.argmax(-1).cpu().numpy())\n",
    "            a_topk = top_k_accuracy_score(y_true=labels, y_score=preds_a.cpu().numpy(), k=top_k)\n",
    "            b_topk = top_k_accuracy_score(y_true=labels, y_score=preds_b.cpu().numpy(), k=top_k)\n",
    "\n",
    "            accs.append((a_acc+b_acc)/2)\n",
    "            topks.append((a_topk+b_topk)/2)\n",
    "\n",
    "            del embedding_anchors\n",
    "            del embedding_replicas\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return np.mean(accs), np.mean(topks), np.std(accs), np.std(topks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586346/3411237818.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_zoo = {'all': test_books.append(test_mails).append(test_blogs),\n"
     ]
    }
   ],
   "source": [
    "model_zoo = {'all': 'model/final_2022-06-21_12-22-26_lstm_books+mails+blogs.ckpt',\n",
    "            'books': 'model/final_2022-06-28_07-55-16_lstm_books.ckpt',\n",
    "            'mails': 'model/final_2022-06-27_08-14-08_lstm_mails.ckpt',\n",
    "            'blogs': 'model/final_2022-06-15_08-10-17_lstm_blogs.ckpt',\n",
    "            }\n",
    "data_zoo = {'all': test_books.append(test_mails).append(test_blogs),\n",
    "            'books': test_books,\n",
    "            'mails': test_mails,\n",
    "            'blogs': test_blogs,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_experimental import ContrastiveLSTMTransformer\n",
    "from random import shuffle\n",
    "\n",
    "REPEATS = 100\n",
    "TOP_K = 5\n",
    "DEVICE = 1\n",
    "\n",
    "n_list = [10, 20, 50, 100, 250]\n",
    "keys = ['all', 'blogs', 'books', 'mails']\n",
    "\n",
    "data_dict = {}\n",
    "# Pass on trained models\n",
    "for k_model in keys:\n",
    "    model_ckpt = model_zoo[k_model]\n",
    "    model = ContrastiveLSTMTransformer.load_from_checkpoint(checkpoint_path=model_ckpt).cuda(DEVICE)\n",
    "\n",
    "    data_dict[f'Model_{k_model}'] = {}\n",
    "    print(f'[log] Evaluating model - {k_model}')\n",
    "\n",
    "    for k_data in keys:\n",
    "        data = data_zoo[k_data]\n",
    "        \n",
    "        data_dict[f'Model_{k_model}'][f'data_{k_data}'] = {}\n",
    "        print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "        for n in n_list:\n",
    "            print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "            max_len = len(data.id.unique())\n",
    "            \n",
    "            if n == 'max':\n",
    "                n = max_len\n",
    "\n",
    "            if n <= max_len:\n",
    "                acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS)\n",
    "                data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "                data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "                print(f'[log] model:{k_model}_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained('roberta-large').cuda(DEVICE)\n",
    "\n",
    "data_dict[f'Model_RoBERTa'] = {}\n",
    "print(f'[log] Evaluating model - RoBERTa')\n",
    "#Base transformer\n",
    "for k_data in keys:\n",
    "    data = data_zoo[k_data]\n",
    "        \n",
    "    data_dict[f'Model_{k_model}'][f'data_{k_data}'] = {}\n",
    "    print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "    for n in n_list:\n",
    "        print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "        max_len = len(data.id.unique())\n",
    "        \n",
    "        if n == 'max':\n",
    "            n = max_len\n",
    "\n",
    "        if n <= max_len:\n",
    "            acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS, embed_f=embed_transformer)\n",
    "            data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "            data_dict[f'Model_{k_model}'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "            print(f'[log] model:{k_model}_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_all</th>\n",
       "      <th>Model_blogs</th>\n",
       "      <th>Model_books</th>\n",
       "      <th>Model_mails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_all</th>\n",
       "      <td>{'N=10 Accuracy': '91.25% ± 7.69', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '90.35% ± 8.67', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '58.25% ± 13.16', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '25.40% ± 11.48', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_blogs</th>\n",
       "      <td>{'N=10 Accuracy': '90.60% ± 8.90', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '91.55% ± 8.21', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '52.60% ± 13.59', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '21.30% ± 10.38', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_books</th>\n",
       "      <td>{'N=10 Accuracy': '87.75% ± 10.08', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '64.15% ± 12.71', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '83.50% ± 11.15', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '26.90% ± 12.22', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_mails</th>\n",
       "      <td>{'N=10 Accuracy': '28.65% ± 9.79', 'N=10 Top-5...</td>\n",
       "      <td>{'N=10 Accuracy': '26.25% ± 11.76', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '21.80% ± 10.62', 'N=10 Top-...</td>\n",
       "      <td>{'N=10 Accuracy': '24.90% ± 12.43', 'N=10 Top-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Model_all  \\\n",
       "data_all    {'N=10 Accuracy': '91.25% ± 7.69', 'N=10 Top-5...   \n",
       "data_blogs  {'N=10 Accuracy': '90.60% ± 8.90', 'N=10 Top-5...   \n",
       "data_books  {'N=10 Accuracy': '87.75% ± 10.08', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '28.65% ± 9.79', 'N=10 Top-5...   \n",
       "\n",
       "                                                  Model_blogs  \\\n",
       "data_all    {'N=10 Accuracy': '90.35% ± 8.67', 'N=10 Top-5...   \n",
       "data_blogs  {'N=10 Accuracy': '91.55% ± 8.21', 'N=10 Top-5...   \n",
       "data_books  {'N=10 Accuracy': '64.15% ± 12.71', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '26.25% ± 11.76', 'N=10 Top-...   \n",
       "\n",
       "                                                  Model_books  \\\n",
       "data_all    {'N=10 Accuracy': '58.25% ± 13.16', 'N=10 Top-...   \n",
       "data_blogs  {'N=10 Accuracy': '52.60% ± 13.59', 'N=10 Top-...   \n",
       "data_books  {'N=10 Accuracy': '83.50% ± 11.15', 'N=10 Top-...   \n",
       "data_mails  {'N=10 Accuracy': '21.80% ± 10.62', 'N=10 Top-...   \n",
       "\n",
       "                                                  Model_mails  \n",
       "data_all    {'N=10 Accuracy': '25.40% ± 11.48', 'N=10 Top-...  \n",
       "data_blogs  {'N=10 Accuracy': '21.30% ± 10.38', 'N=10 Top-...  \n",
       "data_books  {'N=10 Accuracy': '26.90% ± 12.22', 'N=10 Top-...  \n",
       "data_mails  {'N=10 Accuracy': '24.90% ± 12.43', 'N=10 Top-...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/tests_summary.json', 'w') as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/tests_summary.json', 'r') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_all</th>\n",
       "      <th>data_blogs</th>\n",
       "      <th>data_books</th>\n",
       "      <th>data_mails</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>91.25% ± 7.69</td>\n",
       "      <td>90.60% ± 8.90</td>\n",
       "      <td>87.75% ± 10.08</td>\n",
       "      <td>28.65% ± 9.79</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>98.35% ± 3.47</td>\n",
       "      <td>98.25% ± 4.02</td>\n",
       "      <td>98.85% ± 3.31</td>\n",
       "      <td>68.85% ± 10.02</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>86.60% ± 7.16</td>\n",
       "      <td>88.08% ± 6.68</td>\n",
       "      <td>81.45% ± 7.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>95.40% ± 4.28</td>\n",
       "      <td>96.70% ± 3.59</td>\n",
       "      <td>96.28% ± 3.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>83.72% ± 4.60</td>\n",
       "      <td>82.51% ± 4.78</td>\n",
       "      <td>72.14% ± 5.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>93.73% ± 3.54</td>\n",
       "      <td>93.13% ± 3.58</td>\n",
       "      <td>91.94% ± 3.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>78.39% ± 3.99</td>\n",
       "      <td>77.95% ± 3.95</td>\n",
       "      <td>65.07% ± 3.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>90.84% ± 2.55</td>\n",
       "      <td>90.14% ± 2.90</td>\n",
       "      <td>86.49% ± 2.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>72.39% ± 2.39</td>\n",
       "      <td>71.56% ± 2.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>86.73% ± 2.07</td>\n",
       "      <td>85.77% ± 1.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>90.35% ± 8.67</td>\n",
       "      <td>91.55% ± 8.21</td>\n",
       "      <td>64.15% ± 12.71</td>\n",
       "      <td>26.25% ± 11.76</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>97.55% ± 4.50</td>\n",
       "      <td>97.75% ± 4.49</td>\n",
       "      <td>92.75% ± 6.72</td>\n",
       "      <td>67.65% ± 13.52</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>86.67% ± 7.81</td>\n",
       "      <td>87.68% ± 7.95</td>\n",
       "      <td>56.17% ± 9.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>96.10% ± 3.99</td>\n",
       "      <td>96.05% ± 3.97</td>\n",
       "      <td>85.32% ± 6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>82.22% ± 5.16</td>\n",
       "      <td>82.07% ± 4.16</td>\n",
       "      <td>43.74% ± 5.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>93.16% ± 3.60</td>\n",
       "      <td>92.99% ± 3.19</td>\n",
       "      <td>70.78% ± 5.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>77.37% ± 3.94</td>\n",
       "      <td>77.73% ± 3.86</td>\n",
       "      <td>35.94% ± 3.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>90.39% ± 2.99</td>\n",
       "      <td>90.00% ± 2.89</td>\n",
       "      <td>60.44% ± 4.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>70.51% ± 2.74</td>\n",
       "      <td>71.11% ± 2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>85.65% ± 2.19</td>\n",
       "      <td>85.50% ± 2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>58.25% ± 13.16</td>\n",
       "      <td>52.60% ± 13.59</td>\n",
       "      <td>83.50% ± 11.15</td>\n",
       "      <td>21.80% ± 10.62</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>88.85% ± 9.38</td>\n",
       "      <td>87.35% ± 8.84</td>\n",
       "      <td>96.75% ± 4.82</td>\n",
       "      <td>63.40% ± 11.51</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>45.98% ± 11.06</td>\n",
       "      <td>41.62% ± 9.77</td>\n",
       "      <td>77.92% ± 8.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>76.40% ± 8.26</td>\n",
       "      <td>73.10% ± 9.04</td>\n",
       "      <td>93.40% ± 4.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>34.93% ± 6.33</td>\n",
       "      <td>30.62% ± 5.84</td>\n",
       "      <td>70.10% ± 6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>62.19% ± 5.96</td>\n",
       "      <td>57.20% ± 6.55</td>\n",
       "      <td>89.28% ± 3.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>28.06% ± 4.26</td>\n",
       "      <td>24.88% ± 3.35</td>\n",
       "      <td>61.38% ± 4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>50.18% ± 4.94</td>\n",
       "      <td>47.44% ± 4.13</td>\n",
       "      <td>83.51% ± 2.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>20.90% ± 2.09</td>\n",
       "      <td>17.05% ± 1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>38.08% ± 2.73</td>\n",
       "      <td>33.81% ± 2.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>25.40% ± 11.48</td>\n",
       "      <td>21.30% ± 10.38</td>\n",
       "      <td>26.90% ± 12.22</td>\n",
       "      <td>24.90% ± 12.43</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>70.40% ± 14.10</td>\n",
       "      <td>68.10% ± 14.40</td>\n",
       "      <td>70.55% ± 10.84</td>\n",
       "      <td>68.80% ± 12.65</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>18.40% ± 8.76</td>\n",
       "      <td>13.77% ± 6.26</td>\n",
       "      <td>16.93% ± 7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>47.82% ± 11.84</td>\n",
       "      <td>42.43% ± 9.20</td>\n",
       "      <td>48.10% ± 9.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>10.47% ± 4.12</td>\n",
       "      <td>8.56% ± 3.42</td>\n",
       "      <td>8.94% ± 3.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>28.72% ± 6.13</td>\n",
       "      <td>24.13% ± 5.72</td>\n",
       "      <td>27.94% ± 4.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>6.84% ± 1.87</td>\n",
       "      <td>5.47% ± 2.13</td>\n",
       "      <td>6.29% ± 2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>19.39% ± 3.83</td>\n",
       "      <td>15.86% ± 3.45</td>\n",
       "      <td>18.55% ± 3.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>4.27% ± 1.06</td>\n",
       "      <td>3.05% ± 0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>11.87% ± 1.69</td>\n",
       "      <td>8.95% ± 1.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_mails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Accuracy</th>\n",
       "      <td>44.65% ± 15.02</td>\n",
       "      <td>39.20% ± 13.61</td>\n",
       "      <td>44.05% ± 13.98</td>\n",
       "      <td>23.85% ± 10.46</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=10 Top-5 Accuracy</th>\n",
       "      <td>76.55% ± 11.24</td>\n",
       "      <td>72.50% ± 9.39</td>\n",
       "      <td>77.90% ± 10.82</td>\n",
       "      <td>63.00% ± 11.45</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Accuracy</th>\n",
       "      <td>36.95% ± 10.37</td>\n",
       "      <td>34.42% ± 8.93</td>\n",
       "      <td>37.15% ± 9.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=20 Top-5 Accuracy</th>\n",
       "      <td>61.33% ± 9.41</td>\n",
       "      <td>58.30% ± 8.56</td>\n",
       "      <td>63.62% ± 8.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Accuracy</th>\n",
       "      <td>27.65% ± 5.61</td>\n",
       "      <td>24.53% ± 4.80</td>\n",
       "      <td>28.91% ± 6.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=50 Top-5 Accuracy</th>\n",
       "      <td>45.89% ± 6.49</td>\n",
       "      <td>41.34% ± 6.19</td>\n",
       "      <td>50.39% ± 6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Accuracy</th>\n",
       "      <td>23.30% ± 4.01</td>\n",
       "      <td>21.30% ± 3.82</td>\n",
       "      <td>24.23% ± 3.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=100 Top-5 Accuracy</th>\n",
       "      <td>38.09% ± 4.46</td>\n",
       "      <td>34.96% ± 4.17</td>\n",
       "      <td>42.11% ± 3.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Accuracy</th>\n",
       "      <td>18.77% ± 1.99</td>\n",
       "      <td>16.76% ± 1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N=250 Top-5 Accuracy</th>\n",
       "      <td>30.03% ± 2.29</td>\n",
       "      <td>26.94% ± 2.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Model_RoBERTa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            data_all      data_blogs      data_books  \\\n",
       "N=10 Accuracy          91.25% ± 7.69   90.60% ± 8.90  87.75% ± 10.08   \n",
       "N=10 Top-5 Accuracy    98.35% ± 3.47   98.25% ± 4.02   98.85% ± 3.31   \n",
       "N=20 Accuracy          86.60% ± 7.16   88.08% ± 6.68   81.45% ± 7.21   \n",
       "N=20 Top-5 Accuracy    95.40% ± 4.28   96.70% ± 3.59   96.28% ± 3.86   \n",
       "N=50 Accuracy          83.72% ± 4.60   82.51% ± 4.78   72.14% ± 5.34   \n",
       "N=50 Top-5 Accuracy    93.73% ± 3.54   93.13% ± 3.58   91.94% ± 3.26   \n",
       "N=100 Accuracy         78.39% ± 3.99   77.95% ± 3.95   65.07% ± 3.89   \n",
       "N=100 Top-5 Accuracy   90.84% ± 2.55   90.14% ± 2.90   86.49% ± 2.81   \n",
       "N=250 Accuracy         72.39% ± 2.39   71.56% ± 2.45             NaN   \n",
       "N=250 Top-5 Accuracy   86.73% ± 2.07   85.77% ± 1.92             NaN   \n",
       "N=10 Accuracy          90.35% ± 8.67   91.55% ± 8.21  64.15% ± 12.71   \n",
       "N=10 Top-5 Accuracy    97.55% ± 4.50   97.75% ± 4.49   92.75% ± 6.72   \n",
       "N=20 Accuracy          86.67% ± 7.81   87.68% ± 7.95   56.17% ± 9.49   \n",
       "N=20 Top-5 Accuracy    96.10% ± 3.99   96.05% ± 3.97   85.32% ± 6.56   \n",
       "N=50 Accuracy          82.22% ± 5.16   82.07% ± 4.16   43.74% ± 5.90   \n",
       "N=50 Top-5 Accuracy    93.16% ± 3.60   92.99% ± 3.19   70.78% ± 5.69   \n",
       "N=100 Accuracy         77.37% ± 3.94   77.73% ± 3.86   35.94% ± 3.69   \n",
       "N=100 Top-5 Accuracy   90.39% ± 2.99   90.00% ± 2.89   60.44% ± 4.05   \n",
       "N=250 Accuracy         70.51% ± 2.74   71.11% ± 2.78             NaN   \n",
       "N=250 Top-5 Accuracy   85.65% ± 2.19   85.50% ± 2.20             NaN   \n",
       "N=10 Accuracy         58.25% ± 13.16  52.60% ± 13.59  83.50% ± 11.15   \n",
       "N=10 Top-5 Accuracy    88.85% ± 9.38   87.35% ± 8.84   96.75% ± 4.82   \n",
       "N=20 Accuracy         45.98% ± 11.06   41.62% ± 9.77   77.92% ± 8.70   \n",
       "N=20 Top-5 Accuracy    76.40% ± 8.26   73.10% ± 9.04   93.40% ± 4.70   \n",
       "N=50 Accuracy          34.93% ± 6.33   30.62% ± 5.84   70.10% ± 6.62   \n",
       "N=50 Top-5 Accuracy    62.19% ± 5.96   57.20% ± 6.55   89.28% ± 3.78   \n",
       "N=100 Accuracy         28.06% ± 4.26   24.88% ± 3.35   61.38% ± 4.34   \n",
       "N=100 Top-5 Accuracy   50.18% ± 4.94   47.44% ± 4.13   83.51% ± 2.92   \n",
       "N=250 Accuracy         20.90% ± 2.09   17.05% ± 1.96             NaN   \n",
       "N=250 Top-5 Accuracy   38.08% ± 2.73   33.81% ± 2.44             NaN   \n",
       "N=10 Accuracy         25.40% ± 11.48  21.30% ± 10.38  26.90% ± 12.22   \n",
       "N=10 Top-5 Accuracy   70.40% ± 14.10  68.10% ± 14.40  70.55% ± 10.84   \n",
       "N=20 Accuracy          18.40% ± 8.76   13.77% ± 6.26   16.93% ± 7.38   \n",
       "N=20 Top-5 Accuracy   47.82% ± 11.84   42.43% ± 9.20   48.10% ± 9.37   \n",
       "N=50 Accuracy          10.47% ± 4.12    8.56% ± 3.42    8.94% ± 3.49   \n",
       "N=50 Top-5 Accuracy    28.72% ± 6.13   24.13% ± 5.72   27.94% ± 4.98   \n",
       "N=100 Accuracy          6.84% ± 1.87    5.47% ± 2.13    6.29% ± 2.05   \n",
       "N=100 Top-5 Accuracy   19.39% ± 3.83   15.86% ± 3.45   18.55% ± 3.64   \n",
       "N=250 Accuracy          4.27% ± 1.06    3.05% ± 0.89             NaN   \n",
       "N=250 Top-5 Accuracy   11.87% ± 1.69    8.95% ± 1.53             NaN   \n",
       "N=10 Accuracy         44.65% ± 15.02  39.20% ± 13.61  44.05% ± 13.98   \n",
       "N=10 Top-5 Accuracy   76.55% ± 11.24   72.50% ± 9.39  77.90% ± 10.82   \n",
       "N=20 Accuracy         36.95% ± 10.37   34.42% ± 8.93   37.15% ± 9.89   \n",
       "N=20 Top-5 Accuracy    61.33% ± 9.41   58.30% ± 8.56   63.62% ± 8.03   \n",
       "N=50 Accuracy          27.65% ± 5.61   24.53% ± 4.80   28.91% ± 6.14   \n",
       "N=50 Top-5 Accuracy    45.89% ± 6.49   41.34% ± 6.19   50.39% ± 6.47   \n",
       "N=100 Accuracy         23.30% ± 4.01   21.30% ± 3.82   24.23% ± 3.31   \n",
       "N=100 Top-5 Accuracy   38.09% ± 4.46   34.96% ± 4.17   42.11% ± 3.73   \n",
       "N=250 Accuracy         18.77% ± 1.99   16.76% ± 1.86             NaN   \n",
       "N=250 Top-5 Accuracy   30.03% ± 2.29   26.94% ± 2.49             NaN   \n",
       "\n",
       "                          data_mails          Model  \n",
       "N=10 Accuracy          28.65% ± 9.79      Model_all  \n",
       "N=10 Top-5 Accuracy   68.85% ± 10.02      Model_all  \n",
       "N=20 Accuracy                    NaN      Model_all  \n",
       "N=20 Top-5 Accuracy              NaN      Model_all  \n",
       "N=50 Accuracy                    NaN      Model_all  \n",
       "N=50 Top-5 Accuracy              NaN      Model_all  \n",
       "N=100 Accuracy                   NaN      Model_all  \n",
       "N=100 Top-5 Accuracy             NaN      Model_all  \n",
       "N=250 Accuracy                   NaN      Model_all  \n",
       "N=250 Top-5 Accuracy             NaN      Model_all  \n",
       "N=10 Accuracy         26.25% ± 11.76    Model_blogs  \n",
       "N=10 Top-5 Accuracy   67.65% ± 13.52    Model_blogs  \n",
       "N=20 Accuracy                    NaN    Model_blogs  \n",
       "N=20 Top-5 Accuracy              NaN    Model_blogs  \n",
       "N=50 Accuracy                    NaN    Model_blogs  \n",
       "N=50 Top-5 Accuracy              NaN    Model_blogs  \n",
       "N=100 Accuracy                   NaN    Model_blogs  \n",
       "N=100 Top-5 Accuracy             NaN    Model_blogs  \n",
       "N=250 Accuracy                   NaN    Model_blogs  \n",
       "N=250 Top-5 Accuracy             NaN    Model_blogs  \n",
       "N=10 Accuracy         21.80% ± 10.62    Model_books  \n",
       "N=10 Top-5 Accuracy   63.40% ± 11.51    Model_books  \n",
       "N=20 Accuracy                    NaN    Model_books  \n",
       "N=20 Top-5 Accuracy              NaN    Model_books  \n",
       "N=50 Accuracy                    NaN    Model_books  \n",
       "N=50 Top-5 Accuracy              NaN    Model_books  \n",
       "N=100 Accuracy                   NaN    Model_books  \n",
       "N=100 Top-5 Accuracy             NaN    Model_books  \n",
       "N=250 Accuracy                   NaN    Model_books  \n",
       "N=250 Top-5 Accuracy             NaN    Model_books  \n",
       "N=10 Accuracy         24.90% ± 12.43    Model_mails  \n",
       "N=10 Top-5 Accuracy   68.80% ± 12.65    Model_mails  \n",
       "N=20 Accuracy                    NaN    Model_mails  \n",
       "N=20 Top-5 Accuracy              NaN    Model_mails  \n",
       "N=50 Accuracy                    NaN    Model_mails  \n",
       "N=50 Top-5 Accuracy              NaN    Model_mails  \n",
       "N=100 Accuracy                   NaN    Model_mails  \n",
       "N=100 Top-5 Accuracy             NaN    Model_mails  \n",
       "N=250 Accuracy                   NaN    Model_mails  \n",
       "N=250 Top-5 Accuracy             NaN    Model_mails  \n",
       "N=10 Accuracy         23.85% ± 10.46  Model_RoBERTa  \n",
       "N=10 Top-5 Accuracy   63.00% ± 11.45  Model_RoBERTa  \n",
       "N=20 Accuracy                    NaN  Model_RoBERTa  \n",
       "N=20 Top-5 Accuracy              NaN  Model_RoBERTa  \n",
       "N=50 Accuracy                    NaN  Model_RoBERTa  \n",
       "N=50 Top-5 Accuracy              NaN  Model_RoBERTa  \n",
       "N=100 Accuracy                   NaN  Model_RoBERTa  \n",
       "N=100 Top-5 Accuracy             NaN  Model_RoBERTa  \n",
       "N=250 Accuracy                   NaN  Model_RoBERTa  \n",
       "N=250 Top-5 Accuracy             NaN  Model_RoBERTa  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame()\n",
    "for model, d in data_dict.items():\n",
    "    sub_frame = pd.DataFrame(d)\n",
    "    sub_frame['Model'] = model\n",
    "\n",
    "    dataframe = pd.concat([dataframe, sub_frame], axis=0)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "              &                      &        data\\_all &      data\\_blogs &      data\\_books &      data\\_mails \\\\\n",
      "Model & index &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "Model\\_all & N=10 Accuracy &   91.25\\% ± 7.69 &   90.60\\% ± 8.90 &  87.75\\% ± 10.08 &   28.65\\% ± 9.79 \\\\\n",
      "              & N=10 Top-5 Accuracy &   98.35\\% ± 3.47 &   98.25\\% ± 4.02 &   98.85\\% ± 3.31 &  68.85\\% ± 10.02 \\\\\n",
      "              & N=20 Accuracy &   86.60\\% ± 7.16 &   88.08\\% ± 6.68 &   81.45\\% ± 7.21 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   95.40\\% ± 4.28 &   96.70\\% ± 3.59 &   96.28\\% ± 3.86 &             NaN \\\\\n",
      "              & N=50 Accuracy &   83.72\\% ± 4.60 &   82.51\\% ± 4.78 &   72.14\\% ± 5.34 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   93.73\\% ± 3.54 &   93.13\\% ± 3.58 &   91.94\\% ± 3.26 &             NaN \\\\\n",
      "              & N=100 Accuracy &   78.39\\% ± 3.99 &   77.95\\% ± 3.95 &   65.07\\% ± 3.89 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   90.84\\% ± 2.55 &   90.14\\% ± 2.90 &   86.49\\% ± 2.81 &             NaN \\\\\n",
      "              & N=250 Accuracy &   72.39\\% ± 2.39 &   71.56\\% ± 2.45 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   86.73\\% ± 2.07 &   85.77\\% ± 1.92 &             NaN &             NaN \\\\\n",
      "Model\\_blogs & N=10 Accuracy &   90.35\\% ± 8.67 &   91.55\\% ± 8.21 &  64.15\\% ± 12.71 &  26.25\\% ± 11.76 \\\\\n",
      "              & N=10 Top-5 Accuracy &   97.55\\% ± 4.50 &   97.75\\% ± 4.49 &   92.75\\% ± 6.72 &  67.65\\% ± 13.52 \\\\\n",
      "              & N=20 Accuracy &   86.67\\% ± 7.81 &   87.68\\% ± 7.95 &   56.17\\% ± 9.49 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   96.10\\% ± 3.99 &   96.05\\% ± 3.97 &   85.32\\% ± 6.56 &             NaN \\\\\n",
      "              & N=50 Accuracy &   82.22\\% ± 5.16 &   82.07\\% ± 4.16 &   43.74\\% ± 5.90 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   93.16\\% ± 3.60 &   92.99\\% ± 3.19 &   70.78\\% ± 5.69 &             NaN \\\\\n",
      "              & N=100 Accuracy &   77.37\\% ± 3.94 &   77.73\\% ± 3.86 &   35.94\\% ± 3.69 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   90.39\\% ± 2.99 &   90.00\\% ± 2.89 &   60.44\\% ± 4.05 &             NaN \\\\\n",
      "              & N=250 Accuracy &   70.51\\% ± 2.74 &   71.11\\% ± 2.78 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   85.65\\% ± 2.19 &   85.50\\% ± 2.20 &             NaN &             NaN \\\\\n",
      "Model\\_books & N=10 Accuracy &  58.25\\% ± 13.16 &  52.60\\% ± 13.59 &  83.50\\% ± 11.15 &  21.80\\% ± 10.62 \\\\\n",
      "              & N=10 Top-5 Accuracy &   88.85\\% ± 9.38 &   87.35\\% ± 8.84 &   96.75\\% ± 4.82 &  63.40\\% ± 11.51 \\\\\n",
      "              & N=20 Accuracy &  45.98\\% ± 11.06 &   41.62\\% ± 9.77 &   77.92\\% ± 8.70 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   76.40\\% ± 8.26 &   73.10\\% ± 9.04 &   93.40\\% ± 4.70 &             NaN \\\\\n",
      "              & N=50 Accuracy &   34.93\\% ± 6.33 &   30.62\\% ± 5.84 &   70.10\\% ± 6.62 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   62.19\\% ± 5.96 &   57.20\\% ± 6.55 &   89.28\\% ± 3.78 &             NaN \\\\\n",
      "              & N=100 Accuracy &   28.06\\% ± 4.26 &   24.88\\% ± 3.35 &   61.38\\% ± 4.34 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   50.18\\% ± 4.94 &   47.44\\% ± 4.13 &   83.51\\% ± 2.92 &             NaN \\\\\n",
      "              & N=250 Accuracy &   20.90\\% ± 2.09 &   17.05\\% ± 1.96 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   38.08\\% ± 2.73 &   33.81\\% ± 2.44 &             NaN &             NaN \\\\\n",
      "Model\\_mails & N=10 Accuracy &  25.40\\% ± 11.48 &  21.30\\% ± 10.38 &  26.90\\% ± 12.22 &  24.90\\% ± 12.43 \\\\\n",
      "              & N=10 Top-5 Accuracy &  70.40\\% ± 14.10 &  68.10\\% ± 14.40 &  70.55\\% ± 10.84 &  68.80\\% ± 12.65 \\\\\n",
      "              & N=20 Accuracy &   18.40\\% ± 8.76 &   13.77\\% ± 6.26 &   16.93\\% ± 7.38 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &  47.82\\% ± 11.84 &   42.43\\% ± 9.20 &   48.10\\% ± 9.37 &             NaN \\\\\n",
      "              & N=50 Accuracy &   10.47\\% ± 4.12 &    8.56\\% ± 3.42 &    8.94\\% ± 3.49 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   28.72\\% ± 6.13 &   24.13\\% ± 5.72 &   27.94\\% ± 4.98 &             NaN \\\\\n",
      "              & N=100 Accuracy &    6.84\\% ± 1.87 &    5.47\\% ± 2.13 &    6.29\\% ± 2.05 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   19.39\\% ± 3.83 &   15.86\\% ± 3.45 &   18.55\\% ± 3.64 &             NaN \\\\\n",
      "              & N=250 Accuracy &    4.27\\% ± 1.06 &    3.05\\% ± 0.89 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   11.87\\% ± 1.69 &    8.95\\% ± 1.53 &             NaN &             NaN \\\\\n",
      "Model\\_RoBERTa & N=10 Accuracy &  44.65\\% ± 15.02 &  39.20\\% ± 13.61 &  44.05\\% ± 13.98 &  23.85\\% ± 10.46 \\\\\n",
      "              & N=10 Top-5 Accuracy &  76.55\\% ± 11.24 &   72.50\\% ± 9.39 &  77.90\\% ± 10.82 &  63.00\\% ± 11.45 \\\\\n",
      "              & N=20 Accuracy &  36.95\\% ± 10.37 &   34.42\\% ± 8.93 &   37.15\\% ± 9.89 &             NaN \\\\\n",
      "              & N=20 Top-5 Accuracy &   61.33\\% ± 9.41 &   58.30\\% ± 8.56 &   63.62\\% ± 8.03 &             NaN \\\\\n",
      "              & N=50 Accuracy &   27.65\\% ± 5.61 &   24.53\\% ± 4.80 &   28.91\\% ± 6.14 &             NaN \\\\\n",
      "              & N=50 Top-5 Accuracy &   45.89\\% ± 6.49 &   41.34\\% ± 6.19 &   50.39\\% ± 6.47 &             NaN \\\\\n",
      "              & N=100 Accuracy &   23.30\\% ± 4.01 &   21.30\\% ± 3.82 &   24.23\\% ± 3.31 &             NaN \\\\\n",
      "              & N=100 Top-5 Accuracy &   38.09\\% ± 4.46 &   34.96\\% ± 4.17 &   42.11\\% ± 3.73 &             NaN \\\\\n",
      "              & N=250 Accuracy &   18.77\\% ± 1.99 &   16.76\\% ± 1.86 &             NaN &             NaN \\\\\n",
      "              & N=250 Top-5 Accuracy &   30.03\\% ± 2.29 &   26.94\\% ± 2.49 &             NaN &             NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1586346/2621851513.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(dataframe.reset_index().set_index(['Model','index']).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.reset_index().set_index(['Model','index']).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] Evaluating model - RoBERTa\n",
      "[log] Evaluating on data - all\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed23e53a084f9f8fc2f6bde4afc715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:10: 44.65% 76.55%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351fae5593224adba12d551e70b0452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:20: 36.95% 61.33%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3efdd2eabc46a6b6ee106847a3ec8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:50: 27.65% 45.89%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b43327d3f874ba488564077105cbad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:100: 23.30% 38.09%\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88163de980c142c8b780107554212f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:all_n:250: 18.77% 30.03%\n",
      "[log] Evaluating on data - blogs\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc0e036b634b3ba02ed37202922a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:10: 39.20% 72.50%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b8089e31d4483e8c07ceb1a7f82680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:20: 34.42% 58.30%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858eb336ebcb45c791cdb064ebbfbc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:50: 24.53% 41.34%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02cf68d8c174f8aa087e347c129d1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:100: 21.30% 34.96%\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10217ac1aef94c03a3842e1411747fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:blogs_n:250: 16.76% 26.94%\n",
      "[log] Evaluating on data - books\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69a04cf12eb44c091a57e4e25a10e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:10: 44.05% 77.90%\n",
      "[log] Running 100 repetitions for N=20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dad6bfa93ef48f4a2e2734ab6a99768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:20: 37.15% 63.62%\n",
      "[log] Running 100 repetitions for N=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788928e8ff8d4ae7b803316989cbddb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:50: 28.91% 50.39%\n",
      "[log] Running 100 repetitions for N=100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ca8fac90774371bea98f92f3837aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:books_n:100: 24.23% 42.11%\n",
      "[log] Running 100 repetitions for N=250\n",
      "[log] Evaluating on data - mails\n",
      "[log] Running 100 repetitions for N=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47665a46e8e64f5491aba5d75698bb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] model:RoBERTa_data:mails_n:10: 23.85% 63.00%\n",
      "[log] Running 100 repetitions for N=20\n",
      "[log] Running 100 repetitions for N=50\n",
      "[log] Running 100 repetitions for N=100\n",
      "[log] Running 100 repetitions for N=250\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "DEVICE = 1\n",
    "REPEATS = 100\n",
    "TOP_K = 5\n",
    "\n",
    "n_list = [10, 20, 50, 100, 250]\n",
    "keys = ['all', 'blogs', 'books', 'mails']\n",
    "\n",
    "model = AutoModel.from_pretrained('roberta-large').cuda(DEVICE)\n",
    "\n",
    "data_dict[f'Model_RoBERTa'] = {}\n",
    "print(f'[log] Evaluating model - RoBERTa')\n",
    "\n",
    "for k_data in keys:\n",
    "    data = data_zoo[k_data]\n",
    "        \n",
    "    data_dict[f'Model_RoBERTa'][f'data_{k_data}'] = {}\n",
    "    print(f'[log] Evaluating on data - {k_data}')\n",
    "\n",
    "    for n in n_list:\n",
    "        print(f'[log] Running {REPEATS} repetitions for N={n}')\n",
    "        max_len = len(data.id.unique())\n",
    "        \n",
    "        if n == 'max':\n",
    "            n = max_len\n",
    "\n",
    "        if n <= max_len:\n",
    "            acc, topk, acc_sd, topk_sd = evaluate(model, data, top_k=TOP_K, N=n, repetitions=REPEATS, embed_f=embed_transformer)\n",
    "            data_dict[f'Model_RoBERTa'][f'data_{k_data}'][f'N={n} Accuracy'] = f'{100*acc:.2f}% ± {100*acc_sd:.2f}'\n",
    "            data_dict[f'Model_RoBERTa'][f'data_{k_data}'][f'N={n} Top-5 Accuracy'] = f'{100*topk:.2f}% ± {100*topk_sd:.2f}'\n",
    "\n",
    "            print(f'[log] model:RoBERTa_data:{k_data}_n:{n}: {100*acc:.2f}% {100*topk:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
